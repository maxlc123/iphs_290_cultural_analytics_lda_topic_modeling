# -*- coding: utf-8 -*-
"""Copy of demo_class_sa_gutenberg_20201024.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BpIZBTHE1sSAr25JPYaFxLe3eA-5_IiZ

# **Scrape and Preprocess Gutenberg.org books**

References:
* https://github.com/c-w/gutenberg (20200803 241s) Requires some Linux setup
* https://github.com/search?q=texthero
* https://cran.r-project.org/web/packages/syuzhet/index.html

## **0. Setup**
"""

# Enter the unique eBook ID# for the novel you are familiar with by
# looking it up on www.gutenberg.org

my_ebook_no = 2701 # Replace 2701 (Moby Dick) with the Integer number for your eBook ID#

!sudo apt-get install libdb++-dev

!git clone https://github.com/c-w/Gutenberg.git

# Commented out IPython magic to ensure Python compatibility.
# %cd Gutenberg

!pip install .

# Restart may be required

# Click [Reset] button if it appears at the bottom of the previous output block

# If you clicked a [Reset] button, execute this cell to go back into ./Gutenberg dir
# If you didn't see a [Reset] button, just skip executing this block 
# (if you do run it unnecessarily, just ignore the message: "[Errno 2] N such file or..' and continue execution with the next cell)

# %cd Gutenberg

# Set a environment variable needed by gutenberg library

!export BERKELEYDB_DIR=/usr

# Load gutenberg libraries

from gutenberg.acquire import load_etext
from gutenberg.cleanup import strip_headers

# Load metadata libraries

from gutenberg.query import get_etexts
from gutenberg.query import get_metadata

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# # Load metadata data
# 
# from gutenberg.query import list_supported_metadatas
# 
# print(list_supported_metadatas()) # prints (u'author', u'formaturi', u'language', ...)

"""## **1. Get Novel Text**"""

# Retreive a Gutenberg novel by etext number 
# the gutenberg.py library will strip header and footers for us

book_text = strip_headers(load_etext(my_ebook_no)).strip()
print(book_text[:1000])  # prints 'MOBY DICK; OR THE WHALE\n\nBy Herman Melville ...'

# Check the no of char in our book
len(book_text)

# Check the type of variable we've stored our book text in

type(book_text)

# Examine the first 200 characters of our book text

book_text[:200]

# Examine the last 200 characters of our book text

book_text[-200:]

# Write the book text out to a local file

with open("book_dirty.txt", "w") as text_file:
    text_file.write(book_text)

!ls

!pwd

!cat book_dirty.txt

"""## **2. Switch to R and Syuzhet**"""

# Commented out IPython magic to ensure Python compatibility.
# Load the interface to use R from Python 

# %load_ext rpy2.ipython

# Commented out IPython magic to ensure Python compatibility.
# %%R
# install.packages('syuzhet')

# Commented out IPython magic to ensure Python compatibility.
# %%R
# install.packages('zoo')

# Commented out IPython magic to ensure Python compatibility.
# # Read novels in raw text obtained from gutenberg.au
# %%R
# 
# # raw_dalloway_1925 <- get_text_as_string('https://raw.githubusercontent.com/programminghumanity/woolf_4books_sentiment/master/woolf_dalloway_1925.txt')
# raw_book = get_text_as_string('book_dirty.txt')

# Commented out IPython magic to ensure Python compatibility.
# %%R
# 
# # Plot the raw sentence sentiment scores
# 
# syuzhet_vec <- get_sentences(raw_book)
# syuzhet_sentiment_vec <- get_sentiment(syuzhet_vec)
# plot(
#   syuzhet_sentiment_vec, 
#   type="l", 
#   main="Emotional Plot Trajectory", 
#   xlab = "Narrative Time", 
#   ylab= "Emotional Valence"
#   )

# Commented out IPython magic to ensure Python compatibility.
# %%R
# 
# # add a low-pass filter to smooth out the sentiment curve
# 
# ft_values <- get_transformed_values(
#       syuzhet_sentiment_vec, 
#       low_pass_size = 3, 
#       x_reverse_len = 100,
#       padding_factor = 2,
#       scale_vals = TRUE,
#       scale_range = FALSE
# )
#

# Commented out IPython magic to ensure Python compatibility.
# %%R
# 
# # plot the sentiment arc after applying a low-pass filter 
# 
# plot(
#   ft_values, 
#   type ="l", 
#   main ="Your Novel Sentiment Arc using Transformed Values", 
#   xlab = "Narrative Time", 
#   ylab = "Emotional Valence", 
#   col = "red"
# )

# Commented out IPython magic to ensure Python compatibility.
# %%R
# 
# # plot the default 3 smoothing algorithms on sentence sentiment values: 
# # a) sliding window (ragged grey line)
# # b) parameter-free local smoothing with LOESS smoothing
# # c) Discret Cosine Transform smoothing
# 
# # path_to_a_text_file <- system.file("extdata", "bovary.txt", package = "syuzhet")
# # bovary <- get_text_as_string(path_to_a_text_file)
# # bovary_v <- get_sentences(bovary)
# # bovary_sentiment <- get_sentiment(bovary_v)
# 
# simple_plot(syuzhet_sentiment_vec)

"""## **3. Describe 3 plot points/key passages**

Describe 3 plot points/key passages below that you think correspond to any local valley min or peak max of the sentiment arc plots in the the previous cell.

(a) First describe what point your are talking about (e.g. 2nd valley from left, 1st peak from left) and then,

(b) give a several sentence description of the key scene this min/max inflection point corresponds to:

Crux Point #1:
-Inflection Point:
-Corresponding Scene Description:

Crux Point #2:
-Inflection Point:
-Corresponding Scene Description:

Crux Point #3:
-Inflection Point:
-Corresponding Scene Description:

## **4. Save and email us a copy**

Save a copy in your gdrive (File->Save a copy in Drive) and/or download a copy to your laptop (File->Download *.ipynb).  

Email chunj@kenyon.edu and elkinsk@kenyon.edu a copy of this notebook after execution with both:

(a) the computer generated emotional arcs of your novel and,

(b) descriptions in the previous cell of at least 3 min/max inflection points corresponding to key passages/crux points/plot points.
"""

